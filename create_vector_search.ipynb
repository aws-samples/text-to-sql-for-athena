{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd18d7f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define config \n",
    "\n",
    "# Specify the S3 bucket name\n",
    "bucket_name = 'S3_bucket_name'\n",
    "\n",
    "# OpenSearch domain information\n",
    "region = 'region' # Replace with your OpenSearch region\n",
    "host = 'open-search-host' # Replace with your OpenSearch host\n",
    "username = 'username'  # Replace with your OpenSearch username\n",
    "password = 'password'  # Replace with your OpenSearch password\n",
    "\n",
    "index_name = 'vector_search_index'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e51a8c18",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import boto3\n",
    "import os\n",
    "from typing import Optional\n",
    "from botocore.config import Config\n",
    "import os\n",
    "import sys\n",
    "import numpy as np\n",
    "from opensearchpy import OpenSearch, RequestsHttpConnection\n",
    "import time\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ddb8f0cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('imdb_schema.jsonl', 'r') as file:\n",
    "    schema = json.load(file) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b89b1dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the S3 client\n",
    "s3_client = boto3.client('s3')\n",
    "\n",
    "# List all objects in the bucket\n",
    "response = s3_client.list_objects_v2(Bucket=bucket_name)\n",
    "\n",
    "# Retrieve bucket name and keys\n",
    "if 'Contents' in response:\n",
    "    for obj in response['Contents']:\n",
    "        key = obj['Key']\n",
    "        print(f'Bucket: {bucket_name}, Key: {key}')\n",
    "else:\n",
    "    print(\"No objects found in the bucket.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6c3cf15",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create the connection to Bedrock\n",
    "bedrock = boto3.client(\n",
    "    service_name='bedrock',\n",
    "    region_name='us-west-2', \n",
    "    \n",
    ")\n",
    " \n",
    "bedrock_runtime = boto3.client(\n",
    "    service_name='bedrock-runtime',\n",
    "    region_name='us-west-2', \n",
    "    \n",
    ")\n",
    " \n",
    "# Let's see all available Amazon Models\n",
    "available_models = bedrock.list_foundation_models()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50101b65",
   "metadata": {},
   "outputs": [],
   "source": [
    "# confirm available models\n",
    "\n",
    "for model in available_models['modelSummaries']:\n",
    "    print(model['modelId'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1c20614",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_bedrock_client(assumed_role: Optional[str] = None, region: Optional[str] = 'us-east-1',runtime: Optional[bool] = True,external_id=None, ep_url=None):\n",
    "    \"\"\"Create a boto3 client for Amazon Bedrock, with optional configuration overrides \n",
    "    \"\"\"\n",
    "    target_region = region\n",
    "\n",
    "    print(f\"Create new client\\n  Using region: {target_region}:external_id={external_id}: \")\n",
    "    session_kwargs = {\"region_name\": target_region}\n",
    "    client_kwargs = {**session_kwargs}\n",
    "\n",
    "    profile_name = os.environ.get(\"AWS_PROFILE\")\n",
    "    if profile_name:\n",
    "        print(f\"  Using profile: {profile_name}\")\n",
    "        session_kwargs[\"profile_name\"] = profile_name\n",
    "\n",
    "    retry_config = Config(\n",
    "        region_name=target_region,\n",
    "        retries={\n",
    "            \"max_attempts\": 10,\n",
    "            \"mode\": \"standard\",\n",
    "        },\n",
    "    )\n",
    "    session = boto3.Session(**session_kwargs)\n",
    "\n",
    "    if assumed_role:\n",
    "        print(f\"  Using role: {assumed_role}\", end='')\n",
    "        sts = session.client(\"sts\")\n",
    "        if external_id:\n",
    "            response = sts.assume_role(\n",
    "                RoleArn=str(assumed_role),\n",
    "                RoleSessionName=\"langchain-llm-1\",\n",
    "                ExternalId=external_id\n",
    "            )\n",
    "        else:\n",
    "            response = sts.assume_role(\n",
    "                RoleArn=str(assumed_role),\n",
    "                RoleSessionName=\"langchain-llm-1\",\n",
    "            )\n",
    "        print(f\"Using role: {assumed_role} ... sts::successful!\")\n",
    "        client_kwargs[\"aws_access_key_id\"] = response[\"Credentials\"][\"AccessKeyId\"]\n",
    "        client_kwargs[\"aws_secret_access_key\"] = response[\"Credentials\"][\"SecretAccessKey\"]\n",
    "        client_kwargs[\"aws_session_token\"] = response[\"Credentials\"][\"SessionToken\"]\n",
    "\n",
    "    if runtime:\n",
    "        service_name='bedrock-runtime'\n",
    "    else:\n",
    "        service_name='bedrock'\n",
    "\n",
    "    if ep_url:\n",
    "        bedrock_client = session.client(service_name=service_name,config=retry_config,endpoint_url = ep_url, **client_kwargs )\n",
    "    else:\n",
    "        bedrock_client = session.client(service_name=service_name,config=retry_config, **client_kwargs )\n",
    "\n",
    "    print(\"boto3 Bedrock client successfully created!\")\n",
    "    print(bedrock_client._endpoint)\n",
    "    return bedrock_client"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f1e043a",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TitanEmbeddings(object):\n",
    "    accept = \"application/json\"\n",
    "    content_type = \"application/json\"\n",
    "    \n",
    "    def __init__(self, model_id=\"amazon.titan-embed-text-v2:0\", boto3_client=None, region_name='us-east-1'):\n",
    "        \n",
    "        if boto3_client:\n",
    "            self.bedrock_boto3 = boto3_client\n",
    "        else:\n",
    "            # self.bedrock_boto3 = boto3.client(service_name='bedrock-runtime')\n",
    "            self.bedrock_boto3 = boto3.client(\n",
    "                service_name='bedrock-runtime', \n",
    "                region_name=region_name, \n",
    "            )\n",
    "        self.model_id = model_id\n",
    "\n",
    "    def __call__(self, text, dimensions, normalize=True):\n",
    "        \"\"\"\n",
    "        Returns Titan Embeddings\n",
    "\n",
    "        Args:\n",
    "            text (str): text to embed\n",
    "            dimensions (int): Number of output dimensions.\n",
    "            normalize (bool): Whether to return the normalized embedding or not.\n",
    "\n",
    "        Return:\n",
    "            List[float]: Embedding\n",
    "            \n",
    "        \"\"\"\n",
    "\n",
    "        body = json.dumps({\n",
    "            \"inputText\": text,\n",
    "            \"dimensions\": dimensions,\n",
    "            \"normalize\": normalize\n",
    "        })\n",
    "\n",
    "        response = self.bedrock_boto3.invoke_model(\n",
    "            body=body, modelId=self.model_id, accept=self.accept, contentType=self.content_type\n",
    "        )\n",
    "\n",
    "        response_body = json.loads(response.get('body').read())\n",
    "\n",
    "        return response_body['embedding']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5be434c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "boto3_bedrock_runtime = get_bedrock_client() #boto3.client('bedrock')\n",
    "\n",
    "bedrock_embeddings = TitanEmbeddings(model_id=\"amazon.titan-embed-text-v2:0\", boto3_client=boto3_bedrock_runtime)\n",
    "bedrock_embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96f3778c",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TitanV2Model():\n",
    "    def __init__(self) -> None:\n",
    "\n",
    "        self.br_embeddings = None     \n",
    "        self._init_connection()\n",
    "        \n",
    "        print(f\"TitanV2Model:__init__::ready:to:Invoke:::successful::\") \n",
    "    \n",
    "    def _init_connection(self, dim=256):\n",
    "        boto3_bedrock_runtime = get_bedrock_client() #boto3.client('bedrock')\n",
    "\n",
    "        self.br_embeddings = TitanEmbeddings(model_id=\"amazon.titan-embed-text-v2:0\", boto3_client=boto3_bedrock_runtime)\n",
    "        self.dim = dim\n",
    "        \n",
    "    def process_dict_text(self, single_text_dict):\n",
    "        \"\"\" **IMPORTANT** CHANGE this Code to be tuned to your data set and use this -- DO NOT USE THIS AS IS. refer to  https://github.com/embeddings-benchmark/mteb/blob/main/mteb/abstasks/AbsTaskRetrieval.py as an example. Please goover this Git hub in detail\"\"\"\n",
    "        single_text = [str(key).strip() + \" \" + str(val).strip() if 'title' in key.lower() else str(val).strip() for key, val in single_text_dict.items()]\n",
    "        return \" \".join(single_text)[:30000]\n",
    "        \n",
    "    def reorg_text(self, single_text):\n",
    "        \n",
    "        \"\"\" **IMPORTANT** CHANGE this Code to be tuned to your data set and use this -- DO NOT USE THIS AS IS. refer to  https://github.com/embeddings-benchmark/mteb/blob/main/mteb/abstasks/AbsTaskRetrieval.py as an example. Please goover this Git hub in detail\"\"\"\n",
    "        if isinstance(single_text, dict):\n",
    "            single_text = self.process_dict_text(single_text)\n",
    "        single_text = \"0\" if not single_text else single_text \n",
    "        # check for json -- \n",
    "        try:\n",
    "            single_text_dict = json.loads(single_text)\n",
    "            single_text = self.process_dict_text(single_text_dict)\n",
    "        except:\n",
    "            pass\n",
    "        return single_text\n",
    "    \n",
    "    def invoke_model(self, text_list: list[str]):\n",
    "        \"\"\" **IMPORTANT** CHANGE this Code to be tuned to your data set and use this -- DO NOT USE THIS AS IS. refer to  https://github.com/embeddings-benchmark/mteb/blob/main/mteb/abstasks/AbsTaskRetrieval.py as an example. Please goover this Git hub in detail\"\"\"\n",
    "        list_embeddings = []\n",
    "        \n",
    "        for single_text in text_list:\n",
    "            single_text = self.reorg_text(single_text)\n",
    "            single_embed = bedrock_embeddings(text=single_text, dimensions=self.dim, normalize=True)\n",
    "            list_embeddings.append(single_embed)\n",
    "\n",
    "        return list_embeddings\n",
    "\n",
    "    def reshape_titan_embeddings(self, query_embeddings: np.ndarray, **kwargs) -> list[np.ndarray]:\n",
    "        # - use this to re shape your embeddings as needed\n",
    "        return query_embeddings # \n",
    "        \n",
    "        \n",
    "    def encode(self, queries: list[str], **kwargs) -> list[np.ndarray] | list[torch.Tensor] : # - | list[torch.Tensor] \n",
    "        \"\"\"\n",
    "        Returns a list of embeddings for the given sentences.\n",
    "        Args:\n",
    "            queries: List of sentences to encode\n",
    "\n",
    "        Returns:\n",
    "            List of embeddings for the given sentences\n",
    "        \"\"\"\n",
    "        \n",
    "        embedding_list = self.invoke_model(queries)\n",
    "        return self.reshape_titan_embeddings(np.array(embedding_list))\n",
    "\n",
    "    \n",
    "    def encode_queries(self, queries: list[str], **kwargs) -> list[np.ndarray] | list[torch.Tensor] : # - | list[torch.Tensor] \n",
    "        \"\"\"\n",
    "        Returns a list of embeddings for the given sentences.\n",
    "        Args:\n",
    "            queries: List of sentences to encode\n",
    "\n",
    "        Returns:\n",
    "            List of embeddings for the given sentences\n",
    "        \"\"\"\n",
    "        \n",
    "        embedding_list = self.invoke_model(queries)\n",
    "        return self.reshape_titan_embeddings(np.array(embedding_list))\n",
    "\n",
    "\n",
    "    def encode_corpus(self, corpus: list[str] | list[dict[str, str]], **kwargs) -> list[np.ndarray] | list[torch.Tensor] : #- | list[torch.Tensor]:\n",
    "        \"\"\"\n",
    "        Returns a list of embeddings for the given sentences.\n",
    "        Args:\n",
    "            corpus: List of sentences to encode\n",
    "                or list of dictionaries with keys \"title\" and \"text\"\n",
    "\n",
    "        Returns:\n",
    "            List of embeddings for the given sentences\n",
    "        \"\"\"\n",
    "        \n",
    "        embedding_list = self.invoke_model(corpus)\n",
    "        return self.reshape_titan_embeddings(np.array(embedding_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "931374a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_output = TitanV2Model().encode_queries(schema)\n",
    "\n",
    "print(f\"Embneddings Generated ::\")\n",
    "print(f\"shape:of:embeddings -- > length of embeddings={len(final_output)}::\")\n",
    "print(f\"shape:of:embeddings -- > {len(final_output[0])}::\")\n",
    "\n",
    "final_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08a721f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize OpenSearch client with basic authentication\n",
    "client = OpenSearch(\n",
    "    hosts=[{'host': host, 'port': 443}],\n",
    "    http_auth=(username, password),\n",
    "    use_ssl=True,\n",
    "    verify_certs=True,\n",
    "    connection_class=RequestsHttpConnection\n",
    ")\n",
    "\n",
    "# Set number of shards and replicas\n",
    "num_shards = 4\n",
    "\n",
    "index_body = {\n",
    "  'settings': {\n",
    "    'index': {\n",
    "      'number_of_shards': 4,\n",
    "       \"knn\": True \n",
    "    }\n",
    "  },\n",
    "    \n",
    "    \"mappings\": {\n",
    "        \"properties\": {\n",
    "            \"embedding\": {\n",
    "                \"type\": \"knn_vector\",\n",
    "                \"dimension\": 256,  # Adjust this to the dimension of your vectors\n",
    "                \"method\": {\n",
    "                    \"name\": \"hnsw\",\n",
    "                    \"space_type\": \"l2\",\n",
    "                    \"engine\": \"nmslib\",\n",
    "                    \"parameters\": {\n",
    "                        \"ef_construction\": 128,\n",
    "                        \"m\": 16\n",
    "                    }\n",
    "                }\n",
    "            }\n",
    "        }\n",
    "    }\n",
    "}\n",
    "\n",
    "# Create index\n",
    "try:\n",
    "    response = client.indices.create(index=index_name, body=index_body)\n",
    "    print(f\"Index creation response: {response}\")\n",
    "except Exception as e:\n",
    "    print(f\"Error creating index: {str(e)}\")\n",
    "\n",
    "# Verify index existence\n",
    "response = client.indices.exists(index=index_name)\n",
    "print(f\"Index exists: {response}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "203d3e4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, embedding in enumerate(final_output):\n",
    "    document = {\n",
    "        \"embedding\": embedding.tolist()\n",
    "    }\n",
    "    response = client.index(index=index_name, id=f\"doc_{i}\", body=document)\n",
    "    print(f\"Document {i} response: {response}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69c15e31",
   "metadata": {},
   "outputs": [],
   "source": [
    "response = client.indices.exists(index=index_name)\n",
    "print(f\"Index exists: {response}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a51c7f53",
   "metadata": {},
   "source": [
    "# Test\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cff0f357",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example embeddings, replace with actual embeddings\n",
    "embeddings = np.random.rand(256).tolist()\n",
    "\n",
    "# Index a sample document\n",
    "document = {\n",
    "    \"embedding\": embeddings\n",
    "}\n",
    "\n",
    "try:\n",
    "    response = client.index(index=index_name, id=\"doc_1\", body=document)\n",
    "    print(f\"Document indexing response: {response}\")\n",
    "except Exception as e:\n",
    "    print(f\"Error indexing document: {str(e)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f493ca4",
   "metadata": {},
   "outputs": [],
   "source": [
    "query = {\n",
    "    \"size\": 5,\n",
    "    \"query\": {\n",
    "        \"knn\": {\n",
    "            \"embedding\": {\n",
    "                \"vector\": embeddings,\n",
    "                \"k\": 5\n",
    "            }\n",
    "        }\n",
    "    }\n",
    "}\n",
    "\n",
    "try:\n",
    "    response = client.search(index=index_name, body=query)\n",
    "    print(f\"Search response: {response}\")\n",
    "except Exception as e:\n",
    "    print(f\"Error performing search: {str(e)}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_python3",
   "language": "python",
   "name": "conda_python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
